# 第2章总结

概念和术语：观测个数 $n$、变量（特征）个数 $p$；

## 2.1 什么是统计学习

图2.1：用广告费用与销售额的例子引出式(2.1)：广告费用总额不能增加，但可调整各部分比例。

第二个例子，图2.2：受教育年限与收入的关系，单特征；图2.3：多个特征例子。

搞清楚 $f$ 是什么。

### 为什么要估计 $f$

预测和理解。

### 预测 Prediction

获得特征成本低，获得响应成本高，$f$ 可以是个黑盒。

#### 关于偏差(error)

系统误差和随机误差：前者可以降低，后者无法降低；

随机误差存在的原因：未被纳入的特征、无法观测的特征。

严格定义：式(2.3)

随机误差定义了算法精度的上限，实践中往往是未知的。

### 理解(inference)

$X$ 是如何影响 $Y$ 的，$f$ 不能是黑盒。

关心的问题：

* 哪些特征对$Y$有影响？如何找到最重要的影响因素？

* 这些特征与$Y$的关系是什么？正向还是反向？

* 关系是否可以用线性特征表达？线性关系计算成本低，易于理解。

### 场景举例

预测场景：直接推销；direct-market campaign，例如邮件、现场活动、发传单等；

理解场景：哪些媒体广告对销售有帮助；帮助的强弱程度如何？每增加一个单位的电视广告，销售量增加多少？

理解场景2：哪些因素促进超市商品销售？价格、摆放位置、折扣、竟品价格等；

预测+理解场景：房屋价格：受交通、学校、安全度、空气质量等哪些因素影响，影响大小，属于理解，现有价格被高估还是低估，属于预测；

根据需求的不同采用不同的统计学习方法，线性模型理解度高，但精度差，不适合预测，非线性模型精度高适于预测，但理解性差。

### 如何估计$f$

#### 参数化方法

1. 选择模型：即定义 $f$ 的一般形式，例如线性模型（第3章研究）见图2.4，以及公式(2.4)，求解目标变为确定系数；

1. 模型确定后，根据已有数据 训练 模型，采用 最小二乘等方法，第3章研究，更高级的方法在第6章中讨论；

越复杂的模型系数越多，精度越高，过拟合风险越大。

比较图2.4和图2.3。

#### 非参数化方法

非参数化方法不对 $f$ 进行假设，而是尽量接近数据点。

* 优点：避免想当然的 $f$ 与实际情况相差甚远；

* 缺点：需要的训练数据远多于参数化模型；训练成本高；

图2.5和图2.6展示了用样条函数拟合 Income 数据集，前者是合理的复杂度，
后者是过度拟合情形，作者认为这是非参数方式，但实际上仍然可以看成是参数化方法，
比如样条函数的次数，分区个数等。

第5章介绍了如何选择样条的平滑程度，即模型评估（model evaluation）技术，
第7章讨论了样条函数拟合。

### 预测精度与解释性的权衡

图2.7：

* least square, chapter 3;

* lasso, subset selection: chapter 6;

* GAM: chapter 7;

* Bagging, Boosting trees: chapter 8;

* SVM: chapter 9;

### 监督学习和无监督学习

有响应变量的是监督学习，无响应变量的是无监督学习。

线性回归（第3章）、逻辑回归（第4章）、非线性拟合（第6,7,8,9章）都属于监督学习，聚类（第10章）是无监督学习。

图2.8，低维聚类实例，高维聚类使用 $p(p-1)/2$ 个散点图，效果未必好。

半监督学习：部分观测有响应值，部分没有。本书不讨论。

### 回归与分类

数值型 (quantitative) 变量和类别型 (qualitative, categorical) 变量；

回归：响应变量为数值型；分类：响应变量为类别型；

第3章讨论回归问题，第4章讨论分类问题；

KNN (chapter 4), boosting (chapter 8) 可以处理回归和分类问题；

特征是类别型的，则要先编码为数值型的，处理方法在第3章介绍。

## 模型精度评估

### 精度计算

均方差(MSE)，计算公式：式(2.5)

训练均方差，测试均方差：模型是否能“看到”数据；

图2.9（重点）：不同柔软度拟合的训练误差（灰线）、测试误差（红线）；

* 图中的蓝色、绿色线使用的光滑样条在第7章中讨论，水平虚线表示 $Var(\epsilon)$，理论上的最小测试误差；

* 用 自由度 (df) 作为柔软、平滑的指标。

图2.10：线性场景；图2.11：高度非线性场景。

3种场景中，测试误差曲线均单调下降，测试误差曲线都是先下降后上升。

概念：过拟合，test MSE曲线的拐点；

训练误差容易计算，测试误差往往由于不存在测试数据而难于计算。
解决方法：使用交叉验证（cross validation, CV）方法确定最佳参数（第5章）。

### BV均衡

测试误差项的3个成分：式(2.7)

variance 表示训练数据的不同部分得到的模型的差异大小；
bias 表示模型与现实之间的差距；

图2.12（BV均衡，重点）：不同场景（非线性、线性、高度非线性）下bias, variance, test MSE 随柔软度变化的趋势。

现实中test MSE往往无法计算，但这种关系是不变的，算法能力的提升在于能够同时降低B和V。
CV 帮助我们在没有测试数据的情况下降低 test MSE.

### 分类问题

分类问题中误差的计算方法：式(2.8)。

贝叶斯分类器：最大似然方法。

贝叶斯决策边界：概率值等于 0.5 形成的曲线。

贝叶斯错误率（式 2.11）给出了理论上最小错误率。

由于现实问题中条件概率 $Pr(Y = j | X)$ 往往无法计算（朴素贝叶斯做了独立性假设），
贝叶斯分类作为理论上的最优解往往无法计算得到。

图2.14：KNN方法思想：用与 $x_0$ 最近的 $K$ 个点，用这些点中 $Y=j$ 的比例作为
$X=x_0$ 上的条件概率 $Pr(Y = j | X = x_0)$，然后代入贝叶斯公式求出后验概率。
具体公式见 (2.12)。近朱者赤，近墨者黑。

图2.15：KNN边界与贝叶斯边界对比。

图2.16：K越小越柔软，两个K值比较。

图2.17：$\frac1K$作为橫轴，曲线趋势与图2.12一致。

