---
title: "Lab of Chapter 7"
output: html_notebook
---

# 7.8.1 Polynomial Regression and Step Functions
Fit with linear regression and orthogonal polynomials:
```{r}
library(ISLR)
fit <- lm(wage ~ poly(age, 4), data = Wage)
coef(summary(fit))
```

Fit with linear regression and raw polynomials:
---
```{r}
library(ISLR)
fit2 <- lm(wage ~ poly(age, 4, raw = TRUE), data = Wage)
coef(summary(fit2))
coef(fit2)    # same result with above command
```

Fit with linear regression and raw polynomials in another form of formula:
```{r}
fit2a <- lm(wage ~ age + I(age^2) + I(age^3) + I(age^4), data=Wage)
coef(fit2a)
```

Fit with a formula based on `cbind()`:
```{r}
fit2b <- lm(wage ~ cbind(age, age^2, age^3, age^4), data=Wage)
coef(fit2b)
```

Predict wage with age grid:
```{r}
age.range <- range(Wage$age)
age.grid <- seq(from = age.range[1], to = age.range[2])
preds <- predict(fit, list(age = age.grid), se = TRUE)
se.bands <- cbind(preds$fit + 2* preds$se.fit, preds$fit - 2 * preds$se.fit)
```

Plot the data and add the fit from the degree-4 polynomial:
```{r}
par(mfrow = c(1, 2), mar = c(4.5, 4.5, 1, 1), oma = c(0, 0, 4, 0))
plot(Wage$age, Wage$wage, xlim = age.range, cex = 0.5, col = "darkgrey")
title("Degree-4 Polynomial ", outer = T)
lines(age.grid, preds$fit, lwd = 2, col = "blue")
matlines(age.grid, se.bands, lwd = 1, col = "blue", lty = 3)
```

No matter producing an orthogonal set of basis functions with the `poly()` function, or non-orthogonal with `I(x ^ n)`, the predicting result is the same:
```{r}
preds2 <- predict(fit2, list(age = age.grid), se = TRUE)
max(abs(preds$fit - preds2$fit))
```

Find the best model with ANOVA:
```{r}
fit.1 <- lm(wage ~ age, data = Wage)
fit.2 <- lm(wage ~ poly(age, 2), data = Wage)
fit.3 <- lm(wage ~ poly(age, 3), data = Wage)
fit.4 <- lm(wage ~ poly(age, 4), data = Wage)
fit.5 <- lm(wage ~ poly(age, 5), data = Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5)
```

Hence, either a cubic or a quartic polynomial appear to provide a reasonable fit to the data, but lower- or higher-order models are not justified.

Calculating p-value with only `poly()`:
```{r}
coef(summary(fit.5))
```

Notice that the p-values are the same.

The ANOVA method works whether or not we used orthogonal polynomials; it also works when we have other terms in the model as well. For example, we can use anova() to compare these three models:
```{r}
fit.1 <- lm(wage ~ education + age, data = Wage)
fit.2 <- lm(wage ~ education + poly(age, 2), data = Wage)
fit.3 <- lm(wage ~ education + poly(age, 3), data = Wage)
anova(fit.1, fit.2, fit.3)
```

Predicting whether an individual earns more than $250,000 per year:
```{r}
fit <- glm(I(wage > 250) ~ poly(age, 4), data = Wage, family = 'binomial')
preds <- predict(fit, list(age = age.grid), se = TRUE)
pfit <- exp(preds$fit) / (1 + exp(preds$fit))
se.bands.logit <- cbind(preds$fit + 2 * preds$se.fit, preds$fit + 2 * preds$se.fit)
se.bands <- exp(se.bands.logit) / (1 + exp(se.bands.logit))
plot(Wage$age, I(Wage$age > 250), xlim = age.range, type = 'n', ylim = c(0, 0.2))
points(jitter(Wage$age), I((Wage$wage > 250) / 5), cex = 0.5, pch = '|', col = 'darkgray')
lines(age.grid, pfit, lwd = 2, col = 'blue')
matlines(age.grid, se.bands, lwd = 1, col = 'blue', lty = 3)
```

Fit with a step function:
```{r}
table(cut(Wage$age, 4))
fit <- lm(wage ~ cut(age, 4), data = Wage)
coef(summary(fit))
```

# 7.8.2 Splines

Fit age to wage with cubic basis splines, and using a natural spline with 4 degree of freedom:
```{r}
library(splines)
fit <- lm(wage ~ bs(age, knots = c(25, 40, 60)), data = Wage)
preds <- predict(fit, list(age = age.grid), se = TRUE)
plot(Wage$age, Wage$wage, col = 'gray')
lines(age.grid, preds$fit, lwd = 2)
lines(age.grid, preds$fit + 2 * preds$se, lty = 'dashed')
lines(age.grid, preds$fit - 2 * preds$se, lty = 'dashed')

fit2 <- lm(wage ~ ns(age, df = 4), data = Wage)
preds2 <- predict(fit2, list(age = age.grid), se = TRUE)
lines(age.grid, preds2$fit, col = 'red', lwd = 2)
```

Fit with a smooth spline:
```{r}
plot(Wage$age, Wage$wage, xlim = age.range, cex = 0.5, col = 'darkgray')
title("Smoothing Spline")
fit <- smooth.spline(Wage$age, Wage$wage, df = 16)
fit2 <- smooth.spline(Wage$age, Wage$wage, cv = TRUE)
fit2$df
lines(fit, col = 'red', lwd = 2)
lines(fit2, col = 'blue', lwd = 2)
legend("topright", legend = c("16 DF", "6.8 DF"), col = c('red', 'blue'), lty = 1, lwd =2, cex = 0.8)
```

Fit with local regression:
```{r}
plot(Wage$age, Wage$wage, xlim = age.range, cex = 0.5, col = 'darkgray')
title('Local Regression')
fit <- loess(wage ~ age, span = .2, data = Wage)
fit2 <- loess(wage ~ age, span = .5, data = Wage)
lines(age.grid, predict(fit, data.frame(age = age.grid)), col = 'red', lwd = 2)
lines(age.grid, predict(fit2, data.frame(age = age.grid)), col = 'blue', lwd = 2)
legend('topright', legend = c('Span = 0.2', 'Span = 0.5'), col = c('red', 'blue'), lty = 1, lwd = 2, cex = .8)
```



## 对 `bs()` 函数的说明
`bs(x, knots = knots, degree = degree, intercept = TRUE, Boundary.knots = range(x))` 返回一个 `length(x)` 行 `length(knots) + degree + 1` 列矩阵，其中 `x` 是一维实数向量，例如 `seq(0, 3, by = 0.01)`（不需要按顺序排列），`knots` 是 处于 `x` 覆盖范围（例如`range(x)` 是 `[0, 3]`）内的一组叫做节点的实数（例如 `c(0.5, 1.7)`），它的每一列是一个样条 (spline) 函数，这组函数由 `range(x)` 和 knots 以及样条函数的次数 degree 唯一确定，每个样条都保证在节点处 `degree - 1` 阶导数连续，下面的代码演示了在 `[0, 3]` 区间上，包含 0.5, 1.7 两个节点的2次样条(由 $ax^2 + bx +c$ 描述)曲线（共5条）：
```{r}
degree <- 2
x <- sample(seq(0, 3, by = 0.01))  # shuffle x to demonstrate the order (of x) is irrelevant
iknots <- c(0.5, 1.7)

par(mfrow = c(2, 3))
ybs <- bs(x, knots = iknots, degree = degree, intercept = TRUE)
ncol(ybs) == degree + length(iknots) + 1
for (i in 1 : ncol(ybs)) {
  plot(x, ybs[, i], ylab = 'y', main = paste('bs: deg =', degree, 'i = ', i))
}
```
将 `degree` 改为1可以清晰的看到函数曲线在 0.5 和 1.7 保持了连续，随着 `degree` 的升高，节点处连续的导数升高，视觉效果越来越平滑。

`bs()`函数生成的一组函数叫做 [B-spline Basis Functions](http://pages.mtu.edu/~shene/COURSES/cs3621/NOTES/spline/B-spline/bspline-basis.html)，*basis function* 类似于向量空间中的基底向量，各阶函数的计算公式由 *Cox-de Boor recursion formula* 定义，这个公式的初始状态（0阶：$N_{i,0}(u)$）是节点分隔的各个子区间上的阶梯函数，每升一阶自变量 `u` 的阶次增加1，例如 $N_{i,3}(u)$ 是一个`u`的3次方多项式。
上面的链接给出了 `[0, 3]` 区间上，包含 1, 2 两个节点的 0 次到 2 次 basis 函数的手工计算过程。

下面的代码（基于 [A very short note on B-splines](https://www.stat.tamu.edu/~sinha/research/note1.pdf)）给出了 Cox-de Boor recursion formula 的 R 语言实现：
```{r}
basis <- function(x, degree, i, knots) {
  if (degree == 0) {
    if ((x < knots[i + 1]) & (x >= knots[i]))
      y <- 1
    else
      y <- 0
  } else {
    if ((knots[degree+i] - knots[i]) == 0) {
      temp1 <- 0
    } else {
      temp1 <- (x-knots[i]) / (knots[degree+i] - knots[i])
    }
    if ((knots[i + degree + 1] - knots[i + 1]) == 0) {
      temp2 <- 0
    } else {
      temp2 <- (knots[i + degree + 1] - x) / (knots[i + degree + 1] - knots[i + 1])
    }
    y <- temp1 * basis(x, (degree - 1), i, knots) + temp2 * basis(x, (degree - 1), (i + 1), knots)
  }
  return(y)
}

newbs <- function(x, degree, inner.knots, Boundary.knots) {
  Boundary.knots <- sort(Boundary.knots)
  knots <- c(rep(Boundary.knots[1], (degree + 1)),
             sort(inner.knots),
             rep(Boundary.knots[2], (degree + 1)))
  np <- degree + length(inner.knots) + 1
  s <- rep(0, np)
  if (x == Boundary.knots[2]) {
    s[np] <- 1
  } else {
    for (i in 1 : np)
      s[i] <- basis(x, degree, i, knots)
  }
  return(s)
}

lines <- degree + length(iknots) + 1
par(mfrow = c(2, 3))
y <- sapply(x, newbs, degree = degree, inner.knots = iknots, Boundary.knots = range(x))
for (i in 1 : lines) {
  plot(x, y[i, ], ylab = 'y', main = paste('newbs: deg =', degree, 'i = ', i))
}
```

可以证明上述实现与 `bs()` 的计算结果一致：
```{r}
lines == ncol(ybs)
max(t(ybs) - y) < 1e-10     # demonstrate y and ybs are the same
```

为什么 `bs()` 生成的函数组包含`length(knots) + degree + 1` 列，或者说自由度为`length(knots) + degree + 1`？


一段 $d$ 阶样条曲线的自由度是 $(d + 1)$: $\beta_0 + \beta_1 x + \dots + \beta_d x^d$，$K$ 个节点将空间分为 $K+1$ 份，总自由度是 $(d+1) \times (K+1)$，同时在每个节点上有 $d$ 个约束（从 0 到 $d-1$ 阶导数相等），最终自由度是总自由度减去总约束数：
$$
(K + 1) \times (d + 1) - K \times d = K + d + 1
$$

所以7.4.2 节提到3阶样条函数的自由度是 $K + 4$：

> In general, a cubic spline with K knots uses a total of 4 + K degrees of freedom.

以及 7.4.3 节提到：

> ... we perform least squares regression with an intercept and $3 + K$ predictors, of the form $X, X^2, X^3, h(X, \xi_1), h(X, \xi_2), \dots, h(X, \xi_K)$, where $\xi_1, \dots, \xi_K$ are the knots.

这里 $K$ 就是 `length(iknots)`，`degree = 3`，1表示截距 （intercept）。

# 7.8.3 GAMs

Fit with natural splines and linear regression:
```{r}
gam1 <- lm(wage ~ ns(year, 4) + ns(age, 5) + education, data = Wage)
summary(gam1)
par(mfrow = c(1,3))
plot.Gam(gam1, se = TRUE, col = 'red')
```

Note the function name is `plot.Gam()` instead of `plot.gam()`.

Fit with smooth splines and linear regression:
```{r}
library(gam)
gam.m3 <- gam(wage ~ s(year, 4) + s(age, 5) + education, data = Wage)
par(mfrow = c(1,3))
plot(gam.m3, se = TRUE, col = 'blue')
```

Compare 3 models:
```{r}
gam.m1 <- gam(wage ~ s(age, 5) + education, data = Wage)
gam.m2 <- gam(wage ~ year + s(age, 5) + education, data = Wage)
anova(gam.m1, gam.m2, gam.m3, test = "F")
```

To test if there is a non-linear relationship between a feature and the response variable:
```{r}
summary(gam.m3)
```

Note that the output here is different from the book (at the top of page 296).
Here we judge the non-linear relationshop by p-values in section *Anova for Nonparametric Effects*. While this section is called *DF for Terms and F-values for Nonparametric Effects* in the book.

Make predictions on the training set:
```{r}
preds <- predict(gam.m2, Wage)
```

Use local regression in a GAM:
```{r}
gam.lo <- gam(wage ~ s(year, df = 4) + lo(age, span = 0.7) + education, data = Wage)
plot.Gam(gam.lo, se = TRUE, col = 'green')
```

Add interaction item with `lo()` before calling the `gam()`:
```{r}
gam.lo.i <- gam(wage ~ lo(year, age, span = 0.5) + education, data = Wage)
library(akima)
plot(gam.lo.i)
```

Fit a logistic regression GAM:
```{r}
gam.lr <- gam(I(wage > 250) ~ year + s(age, df = 5) + education, family = binomial, data = Wage)
par(mfrow = c(1,1))
plot(gam.lr, se = TRUE, col = 'green')
```

See the relationship between a qualitative feature and the response:
```{r}
table(Wage$education, I(Wage$wage > 250))
```

Fit a logistic regression GAM using all but a selected category:
```{r}
gam.lr.s <- gam(I(wage > 250) ~ year + s(age, df = 5) + education, family = binomial, data = Wage, subset = (education != "1. < HS Grad"))
plot(gam.lr.s, se = TRUE, col = 'green')
```

