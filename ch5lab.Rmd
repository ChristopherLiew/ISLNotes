---
title: "Lab of Chapter 5"
output: html_notebook
---

# 5.3.1 The Validation Set Approach
Select training set from population randomly for the first time:
```{r}
library(ISLR)
set.seed(1)
train <- sample(nrow(Auto), 0.5 * nrow(Auto))
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit, Auto))[-train] ^ 2)

lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit2, Auto))[-train] ^ 2)

lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit3, Auto))[-train] ^ 2)
```
Select training set from population randomly for the second time:
```{r}
set.seed(2)
train <- sample(nrow(Auto), 0.5 * nrow(Auto))
lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit, Auto))[-train] ^ 2)

lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit2, Auto))[-train] ^ 2)

lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
mean((Auto$mpg - predict(lm.fit3, Auto))[-train] ^ 2)
```

# 5.3.2 Leave-One-Out Cross-Validation
LOOCV method:
```{r}
library(boot)
glm.fit <- glm(mpg ~ horsepower, data = Auto)
cv.error <- cv.glm(Auto, glm.fit)
cv.error$delta
```

> The first is the standard k-fold CV estimate, as in (5.3). The second is a bias-corrected version.

LOOCV with high order regression method:
```{r}
cv.err <- rep(0, 5)
for (i in 1:5) {
  glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err[i] <- cv.glm(Auto, glm.fit)$delta[1]
}
cv.err
```

# 5.3.3 k-Fold Cross-Validation

```{r}
set.seed(17)
cv.err.10 <- rep(0, 10)
for (i in 1:10) {
  glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)
  cv.err.10[i] <- cv.glm(Auto, glm.fit)$delta[1]
}
cv.err.10
```

# 5.3.4 The Bootstrap

## Estimating the Accuracy of a Statistic of Interest
```{r}
alpha.fn <- function(data, index) {
  X <- data$X[index]
  Y <- data$Y[index]
  (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2* cov(X, Y))
}
alpha.fn(Portfolio, 1:100)
set.seed(1)
alpha.fn(Portfolio, sample(100, 100, replace = TRUE))
boot(Portfolio, alpha.fn, R = 1000)
```

## Estimating the Accuracy of a Linear Regression Model
Get coefficients with basic linear regression:
```{r}
boot.fn <- function(data, index) coef(lm(mpg ~ horsepower, data = data, subset = index))
all.obs <- nrow(Auto)
boot.fn(Auto, 1:all.obs)
```

With bootstrap:
```{r}
set.seed(1)
boot.fn(Auto, sample(all.obs, all.obs, replace = TRUE))
boot.fn(Auto, sample(all.obs, all.obs, replace = TRUE))
```

Compare coefficients calculated with bootstrap and equation (3.8):
```{r}
boot(Auto, boot.fn, R = 1000)
summary(lm(mpg ~ horsepower, data = Auto))$coef
```

Compare with a quadratic model:
```{r}
boot.fn2 <- function(data, index) coef(lm(mpg ~ horsepower + I(horsepower^2), data = data, subset = index))
set.seed(1)
boot(Auto, boot.fn2, R = 1000)
summary(lm(mpg ~ horsepower + I(horsepower^2), data = Auto))$coef
```

Why `poly()` and `I()` produce different results?
```{r}
boot.fn2 <- function(data, index) coef(lm(mpg ~ poly(horsepower, 2), data = data, subset = index))
set.seed(1)
boot(Auto, boot.fn2, R = 1000)
summary(lm(mpg ~ poly(horsepower, 2), data = Auto))$coef
```